{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading market data for AAPL from 2025-03-08 11:44:26.205933 to 2025-04-07 11:44:26.205933\n",
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download AAPL data: 'NotImplementedType' object has no attribute '_indexed_same'\n",
      "Insufficient data for AAPL\n",
      "Downloading market data for AAPL from 2025-03-08 11:44:26.590919 to 2025-04-07 11:44:26.590919\n",
      "Failed to download AAPL data: 'NotImplementedType' object has no attribute '_indexed_same'\n",
      "Skipping AAPL due to insufficient data\n",
      "Downloading market data for MSFT from 2025-03-08 11:44:26.635093 to 2025-04-07 11:44:26.635093\n",
      "Failed to download MSFT data: 'NotImplementedType' object has no attribute '_indexed_same'\n",
      "Skipping MSFT due to insufficient data\n",
      "Downloading market data for GOOGL from 2025-03-08 11:44:26.769491 to 2025-04-07 11:44:26.769491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download GOOGL data: 'NotImplementedType' object has no attribute '_indexed_same'\n",
      "Skipping GOOGL due to insufficient data\n",
      "Downloading market data for AMZN from 2025-03-08 11:44:26.837179 to 2025-04-07 11:44:26.837179\n",
      "Failed to download AMZN data: 'NotImplementedType' object has no attribute '_indexed_same'\n",
      "Skipping AMZN due to insufficient data\n",
      "Downloading market data for META from 2025-03-08 11:44:26.916729 to 2025-04-07 11:44:26.916729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download META data: 'NotImplementedType' object has no attribute '_indexed_same'\n",
      "Skipping META due to insufficient data\n",
      "Downloading market data for NVDA from 2025-03-08 11:44:27.079229 to 2025-04-07 11:44:27.079229\n",
      "Failed to download NVDA data: 'NotImplementedType' object has no attribute '_indexed_same'\n",
      "Skipping NVDA due to insufficient data\n",
      "Downloading market data for TSLA from 2025-03-08 11:44:27.203972 to 2025-04-07 11:44:27.203972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download TSLA data: 'NotImplementedType' object has no attribute '_indexed_same'\n",
      "Skipping TSLA due to insufficient data\n",
      "No correlation data generated\n",
      "Downloading market data for AAPL from 2025-03-08 11:44:27.285392 to 2025-04-07 11:44:27.285392\n",
      "Failed to download AAPL data: 'NotImplementedType' object has no attribute '_indexed_same'\n",
      "Downloading market data for MSFT from 2025-03-08 11:44:27.362923 to 2025-04-07 11:44:27.362923\n",
      "Failed to download MSFT data: 'NotImplementedType' object has no attribute '_indexed_same'\n",
      "Downloading market data for GOOGL from 2025-03-08 11:44:27.431922 to 2025-04-07 11:44:27.431922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download GOOGL data: 'NotImplementedType' object has no attribute '_indexed_same'\n",
      "Downloading market data for AMZN from 2025-03-08 11:44:27.519107 to 2025-04-07 11:44:27.519107\n",
      "Failed to download AMZN data: 'NotImplementedType' object has no attribute '_indexed_same'\n",
      "Downloading market data for META from 2025-03-08 11:44:27.622221 to 2025-04-07 11:44:27.622221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download META data: 'NotImplementedType' object has no attribute '_indexed_same'\n",
      "Downloading market data for NVDA from 2025-03-08 11:44:27.741264 to 2025-04-07 11:44:27.741264\n",
      "Failed to download NVDA data: 'NotImplementedType' object has no attribute '_indexed_same'\n",
      "Downloading market data for TSLA from 2025-03-08 11:44:27.786432 to 2025-04-07 11:44:27.786432\n",
      "Failed to download TSLA data: 'NotImplementedType' object has no attribute '_indexed_same'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 602\u001b[0m\n\u001b[1;32m    600\u001b[0m dashboard \u001b[38;5;241m=\u001b[39m visualizer\u001b[38;5;241m.\u001b[39mcreate_sentiment_impact_dashboard(tech_tickers, days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dashboard:\n\u001b[0;32m--> 602\u001b[0m     \u001b[43mdashboard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Analyze sentiment patterns for Apple\u001b[39;00m\n\u001b[1;32m    605\u001b[0m patterns \u001b[38;5;241m=\u001b[39m visualizer\u001b[38;5;241m.\u001b[39manalyze_sentiment_patterns(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m\"\u001b[39m, days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/MSC-PROJECT/stock-prediction/env/lib/python3.10/site-packages/plotly/basedatatypes.py:3414\u001b[0m, in \u001b[0;36mBaseFigure.show\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3381\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3382\u001b[0m \u001b[38;5;124;03mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[1;32m   3383\u001b[0m \u001b[38;5;124;03mspecified by the renderer argument\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3410\u001b[0m \u001b[38;5;124;03mNone\u001b[39;00m\n\u001b[1;32m   3411\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3412\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpio\u001b[39;00m\n\u001b[0;32m-> 3414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MSC-PROJECT/stock-prediction/env/lib/python3.10/site-packages/plotly/io/_renderers.py:425\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    421\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    422\u001b[0m     )\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    427\u001b[0m     )\n\u001b[1;32m    429\u001b[0m display_jupyter_version_warnings()\n\u001b[1;32m    431\u001b[0m ipython_display\u001b[38;5;241m.\u001b[39mdisplay(bundle, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "# Sentiment vs Stock Price Analysis with Mock Data\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class SentimentStockVisualizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def generate_mock_sentiment_data(self, ticker, start_date, end_date):\n",
    "        \"\"\"\n",
    "        Generate mock sentiment data for visualization purposes\n",
    "        \"\"\"\n",
    "        # Create date range\n",
    "        date_range = pd.date_range(start=start_date, end=end_date, freq='1H')\n",
    "        \n",
    "        # Generate synthetic sentiment data with some correlation to stock movements\n",
    "        np.random.seed(42)  # For reproducibility\n",
    "        \n",
    "        # Base sentiment - random walk with mean reversion\n",
    "        base_sentiment = np.random.normal(0.5, 0.1, len(date_range))\n",
    "        # Apply some smoothing to simulate trends\n",
    "        sentiment_smooth = pd.Series(base_sentiment).rolling(window=24, min_periods=1).mean().values\n",
    "        \n",
    "        # Generate other metrics\n",
    "        mentions_count = np.random.poisson(20, len(date_range))\n",
    "        social_impact = np.random.gamma(2, 10, len(date_range))\n",
    "        \n",
    "        # Create DataFrame\n",
    "        sentiment_df = pd.DataFrame({\n",
    "            'sentiment_score': sentiment_smooth,\n",
    "            'mentions_count': mentions_count,\n",
    "            'social_impact': social_impact\n",
    "        }, index=date_range)\n",
    "        \n",
    "        return sentiment_df\n",
    "        \n",
    "    def fetch_data_for_visualization(self, ticker, days=30):\n",
    "        \"\"\"\n",
    "        Fetch stock data and generate mock sentiment data\n",
    "        \"\"\"\n",
    "        try:\n",
    "            end_date = datetime.now()\n",
    "            start_date = end_date - timedelta(days=days)\n",
    "            \n",
    "            print(f\"Downloading market data for {ticker} from {start_date} to {end_date}\")\n",
    "            stock_data = yf.download(ticker, start=start_date, end=end_date, interval=\"1h\")\n",
    "            \n",
    "            if stock_data.empty:\n",
    "                print(f\"No market data found for {ticker}\")\n",
    "                return None, None\n",
    "                \n",
    "            # Generate mock sentiment data\n",
    "            sentiment_df = self.generate_mock_sentiment_data(ticker, start_date, end_date)\n",
    "            \n",
    "            # Align indices\n",
    "            common_dates = sentiment_df.index.intersection(stock_data.index)\n",
    "            if len(common_dates) < 10:  # Need at least 10 data points\n",
    "                # Recreate sentiment data using stock data dates to ensure alignment\n",
    "                sentiment_df = self.generate_mock_sentiment_data(ticker, \n",
    "                                                              stock_data.index[0], \n",
    "                                                              stock_data.index[-1])\n",
    "                # Now match up the indices again\n",
    "                sentiment_df = sentiment_df.reindex(stock_data.index, method='nearest')\n",
    "            else:\n",
    "                sentiment_df = sentiment_df.loc[common_dates]\n",
    "                stock_data = stock_data.loc[common_dates]\n",
    "                \n",
    "            # Add some correlation with the stock data\n",
    "            # This makes the mock data more realistic by slightly correlating sentiment with price changes\n",
    "            price_changes = stock_data['Close'].pct_change().fillna(0)\n",
    "            noise_factor = 0.3  # How much the price affects sentiment\n",
    "            sentiment_df['sentiment_score'] += price_changes.shift(3) * noise_factor  # Lagged effect\n",
    "            sentiment_df['sentiment_score'] = sentiment_df['sentiment_score'].clip(0, 1)  # Keep in 0-1 range\n",
    "            \n",
    "            print(f\"Generated {len(sentiment_df)} records of mock sentiment data for {ticker}\")\n",
    "            return sentiment_df, stock_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download {ticker} data: {str(e)}\")\n",
    "            return None, None\n",
    "        \n",
    "    def create_correlation_plot(self, ticker, days=30):\n",
    "        \"\"\"\n",
    "        Create correlation plot between sentiment and stock price\n",
    "        \"\"\"\n",
    "        sentiment_df, stock_data = self.fetch_data_for_visualization(ticker, days)\n",
    "        \n",
    "        if sentiment_df is None or stock_data is None:\n",
    "            print(f\"Insufficient data for {ticker}\")\n",
    "            return\n",
    "            \n",
    "        # Merge datasets\n",
    "        try:\n",
    "            # Resample both datasets to hourly to ensure alignment\n",
    "            stock_data_resampled = stock_data.resample('1H').last().dropna()\n",
    "            sentiment_resampled = sentiment_df.resample('1H').mean().dropna()\n",
    "            \n",
    "            # Merge data\n",
    "            merged = pd.merge(\n",
    "                sentiment_resampled,\n",
    "                stock_data_resampled,\n",
    "                left_index=True,\n",
    "                right_index=True,\n",
    "                how='inner'\n",
    "            )\n",
    "            \n",
    "            if merged.empty:\n",
    "                print(f\"No overlapping data found for {ticker}\")\n",
    "                return\n",
    "                \n",
    "            # Calculate price changes\n",
    "            merged['price_change'] = merged['Close'].pct_change()\n",
    "            merged['price_change_next'] = merged['Close'].pct_change().shift(-1)\n",
    "            merged = merged.dropna()\n",
    "            \n",
    "            # Calculate lagged sentiment correlations\n",
    "            lags = range(1, 13)  # Check correlations up to 12 hours\n",
    "            correlations = {}\n",
    "            \n",
    "            for lag in lags:\n",
    "                merged[f'sentiment_lag_{lag}'] = merged['sentiment_score'].shift(lag)\n",
    "                corr = merged['price_change'].corr(merged[f'sentiment_lag_{lag}'])\n",
    "                correlations[lag] = corr\n",
    "                \n",
    "            # Plot correlation data\n",
    "            fig = make_subplots(\n",
    "                rows=2, cols=1,\n",
    "                subplot_titles=(\n",
    "                    f\"{ticker} Sentiment vs. Stock Price\", \n",
    "                    \"Lagged Sentiment Correlation with Price Changes\"\n",
    "                ),\n",
    "                vertical_spacing=0.15,\n",
    "                specs=[[{\"secondary_y\": True}], [{\"secondary_y\": False}]]\n",
    "            )\n",
    "            \n",
    "            # Add sentiment and price to first subplot\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=merged.index,\n",
    "                    y=merged['sentiment_score'],\n",
    "                    name='Sentiment Score',\n",
    "                    line=dict(color='blue')\n",
    "                ),\n",
    "                row=1, col=1\n",
    "            )\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=merged.index,\n",
    "                    y=merged['Close'],\n",
    "                    name='Stock Price',\n",
    "                    line=dict(color='green')\n",
    "                ),\n",
    "                row=1, col=1, secondary_y=True\n",
    "            )\n",
    "            \n",
    "            # Add correlation by lag to second subplot\n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    x=list(correlations.keys()),\n",
    "                    y=list(correlations.values()),\n",
    "                    name='Correlation',\n",
    "                    marker_color='purple'\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "            \n",
    "            # Update layout\n",
    "            fig.update_layout(\n",
    "                height=800,\n",
    "                title_text=f\"Sentiment Analysis Impact on {ticker} Stock Price\",\n",
    "                hovermode=\"x unified\"\n",
    "            )\n",
    "            \n",
    "            fig.update_yaxes(title_text=\"Sentiment Score\", row=1, col=1)\n",
    "            fig.update_yaxes(title_text=\"Stock Price ($)\", row=1, col=1, secondary_y=True)\n",
    "            fig.update_xaxes(title_text=\"Date\", row=1, col=1)\n",
    "            fig.update_xaxes(title_text=\"Lag (Hours)\", row=2, col=1)\n",
    "            fig.update_yaxes(title_text=\"Correlation\", row=2, col=1)\n",
    "            \n",
    "            return fig\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating correlation plot: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def create_heatmap(self, tickers, days=30):\n",
    "        \"\"\"\n",
    "        Create a heatmap showing sentiment-price correlations across multiple tickers\n",
    "        \"\"\"\n",
    "        correlation_data = {}\n",
    "        \n",
    "        for ticker in tickers:\n",
    "            sentiment_df, stock_data = self.fetch_data_for_visualization(ticker, days)\n",
    "            \n",
    "            if sentiment_df is None or stock_data is None:\n",
    "                print(f\"Skipping {ticker} due to insufficient data\")\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                # Resample and merge\n",
    "                stock_data_resampled = stock_data.resample('1H').last().dropna()\n",
    "                sentiment_resampled = sentiment_df.resample('1H').mean().dropna()\n",
    "                \n",
    "                merged = pd.merge(\n",
    "                    sentiment_resampled,\n",
    "                    stock_data_resampled['Close'],\n",
    "                    left_index=True,\n",
    "                    right_index=True,\n",
    "                    how='inner'\n",
    "                )\n",
    "                \n",
    "                if merged.empty:\n",
    "                    continue\n",
    "                    \n",
    "                # Calculate correlations\n",
    "                correlation = merged['sentiment_score'].corr(merged['Close'])\n",
    "                correlation_data[ticker] = correlation\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {ticker}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if not correlation_data:\n",
    "            print(\"No correlation data generated\")\n",
    "            return None\n",
    "            \n",
    "        # Create heatmap\n",
    "        correlations = pd.Series(correlation_data)\n",
    "        correlations = correlations.sort_values(ascending=False)\n",
    "        \n",
    "        fig = px.bar(\n",
    "            x=correlations.index,\n",
    "            y=correlations.values,\n",
    "            title=\"Sentiment-Price Correlation by Tech Company\",\n",
    "            labels={'x': 'Ticker', 'y': 'Correlation'},\n",
    "            color=correlations.values,\n",
    "            color_continuous_scale=\"RdBu\",\n",
    "            text=correlations.values.round(2)\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(height=600)\n",
    "        fig.update_traces(texttemplate='%{text:.2f}', textposition='outside')\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def create_sentiment_impact_dashboard(self, tickers, days=30):\n",
    "        \"\"\"\n",
    "        Create a comprehensive dashboard showing sentiment impact\n",
    "        \"\"\"\n",
    "        sentiment_trends = {}\n",
    "        price_trends = {}\n",
    "        impact_scores = {}\n",
    "        \n",
    "        for ticker in tickers:\n",
    "            sentiment_df, stock_data = self.fetch_data_for_visualization(ticker, days)\n",
    "            \n",
    "            if sentiment_df is None or stock_data is None:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                # Daily aggregation for dashboard\n",
    "                daily_sentiment = sentiment_df.resample('D').mean()\n",
    "                daily_stock = stock_data.resample('D').last()\n",
    "                \n",
    "                # Store trends\n",
    "                sentiment_trends[ticker] = daily_sentiment['sentiment_score'].tolist()\n",
    "                price_trends[ticker] = daily_stock['Close'].tolist()\n",
    "                \n",
    "                # Calculate impact score\n",
    "                merged = pd.merge(\n",
    "                    daily_sentiment,\n",
    "                    daily_stock['Close'],\n",
    "                    left_index=True,\n",
    "                    right_index=True,\n",
    "                    how='inner'\n",
    "                )\n",
    "                \n",
    "                # Create impact score based on correlation and volatility\n",
    "                correlation = merged['sentiment_score'].corr(merged['Close'])\n",
    "                price_volatility = merged['Close'].pct_change().std()\n",
    "                sentiment_volatility = merged['sentiment_score'].pct_change().std()\n",
    "                \n",
    "                impact_score = abs(correlation) * (price_volatility * sentiment_volatility * 100)\n",
    "                impact_scores[ticker] = impact_score\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {ticker} for dashboard: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Create dashboard visualization\n",
    "        dates = pd.date_range(end=datetime.now(), periods=days).tolist()\n",
    "        \n",
    "        # Create figure\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=(\n",
    "                \"Sentiment Impact Score by Company\",\n",
    "                \"Average Sentiment Trend\",\n",
    "                \"Stock Price Trends (Normalized)\",\n",
    "                \"Sentiment vs Price Movement\"\n",
    "            ),\n",
    "            specs=[\n",
    "                [{\"type\": \"bar\"}, {\"type\": \"scatter\"}],\n",
    "                [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}]\n",
    "            ],\n",
    "            vertical_spacing=0.12,\n",
    "            horizontal_spacing=0.08\n",
    "        )\n",
    "        \n",
    "        # Plot 1: Impact score by company\n",
    "        impact_df = pd.Series(impact_scores).sort_values(ascending=False)\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=impact_df.index,\n",
    "                y=impact_df.values,\n",
    "                marker_color='rgb(55, 83, 109)'\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Plot 2: Sentiment trends\n",
    "        for ticker, values in sentiment_trends.items():\n",
    "            if len(values) < len(dates):\n",
    "                # Pad with NaN if needed\n",
    "                values = [np.nan] * (len(dates) - len(values)) + values\n",
    "            else:\n",
    "                # Trim if too long\n",
    "                values = values[-len(dates):]\n",
    "                \n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=dates[-len(values):],\n",
    "                    y=values,\n",
    "                    name=ticker,\n",
    "                    mode='lines'\n",
    "                ),\n",
    "                row=1, col=2\n",
    "            )\n",
    "        \n",
    "        # Plot 3: Normalized price trends\n",
    "        for ticker, values in price_trends.items():\n",
    "            if len(values) < len(dates):\n",
    "                continue\n",
    "                \n",
    "            # Normalize prices to percentage change from start\n",
    "            normalized = [(v/values[0]-1)*100 for v in values]\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=dates[-len(normalized):],\n",
    "                    y=normalized,\n",
    "                    name=ticker,\n",
    "                    mode='lines'\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "        \n",
    "        # Plot 4: Sample detail view for first ticker\n",
    "        if tickers and tickers[0] in sentiment_trends and tickers[0] in price_trends:\n",
    "            ticker = tickers[0]\n",
    "            \n",
    "            sentiment_df, stock_data = self.fetch_data_for_visualization(ticker, days)\n",
    "            if sentiment_df is not None and stock_data is not None:\n",
    "                # Daily data\n",
    "                daily_sent = sentiment_df.resample('D').mean()\n",
    "                daily_price = stock_data.resample('D').last()\n",
    "                \n",
    "                # Create dual axis plot\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=daily_sent.index,\n",
    "                        y=daily_sent['sentiment_score'],\n",
    "                        name='Sentiment',\n",
    "                        line=dict(color='blue')\n",
    "                    ),\n",
    "                    row=2, col=2\n",
    "                )\n",
    "                \n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=daily_price.index,\n",
    "                        y=daily_price['Close'],\n",
    "                        name='Price',\n",
    "                        yaxis=\"y2\",\n",
    "                        line=dict(color='green')\n",
    "                    ),\n",
    "                    row=2, col=2\n",
    "                )\n",
    "                \n",
    "                # Add second y-axis\n",
    "                fig.update_layout(\n",
    "                    yaxis4=dict(\n",
    "                        title=\"Sentiment\",\n",
    "                        side=\"left\"\n",
    "                    ),\n",
    "                    yaxis5=dict(\n",
    "                        title=f\"{ticker} Price ($)\",\n",
    "                        side=\"right\",\n",
    "                        overlaying=\"y4\"\n",
    "                    )\n",
    "                )\n",
    "        \n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            height=900,\n",
    "            width=1100,\n",
    "            title_text=\"Tech Company Sentiment Impact Dashboard\",\n",
    "            showlegend=False,\n",
    "            hovermode=\"closest\"\n",
    "        )\n",
    "        \n",
    "        # Update axes titles\n",
    "        fig.update_xaxes(title_text=\"Company\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"Impact Score\", row=1, col=1)\n",
    "        \n",
    "        fig.update_xaxes(title_text=\"Date\", row=1, col=2)\n",
    "        fig.update_yaxes(title_text=\"Sentiment Score\", row=1, col=2)\n",
    "        \n",
    "        fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"Price Change (%)\", row=2, col=1)\n",
    "        \n",
    "        fig.update_xaxes(title_text=\"Date\", row=2, col=2)\n",
    "        \n",
    "        return fig\n",
    "\n",
    "    def analyze_sentiment_patterns(self, ticker, days=30):\n",
    "        \"\"\"\n",
    "        Analyze and visualize patterns in sentiment and their relationship to key market events\n",
    "        \"\"\"\n",
    "        sentiment_df, stock_data = self.fetch_data_for_visualization(ticker, days)\n",
    "        \n",
    "        if sentiment_df is None or stock_data is None:\n",
    "            print(f\"Insufficient data for {ticker}\")\n",
    "            return None\n",
    "            \n",
    "        # Detect key events (significant price movements)\n",
    "        stock_daily = stock_data.resample('D').last()\n",
    "        stock_daily['returns'] = stock_daily['Close'].pct_change()\n",
    "        \n",
    "        # Define significant events as days with returns > 1.5 std dev\n",
    "        std_dev = stock_daily['returns'].std()\n",
    "        threshold = 1.5 * std_dev\n",
    "        \n",
    "        significant_events = stock_daily[abs(stock_daily['returns']) > threshold].copy()\n",
    "        significant_events['event_type'] = significant_events['returns'].apply(\n",
    "            lambda x: 'Positive' if x > 0 else 'Negative'\n",
    "        )\n",
    "        \n",
    "        # Resample to daily for cleaner visualization\n",
    "        sentiment_daily = sentiment_df.resample('D').mean()\n",
    "        \n",
    "        # Calculate some metrics\n",
    "        sentiment_daily['smoothed'] = sentiment_daily['sentiment_score'].rolling(3).mean()\n",
    "        sentiment_daily['momentum'] = sentiment_daily['sentiment_score'].diff(3)\n",
    "        \n",
    "        # Create the visualization\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=1,\n",
    "            subplot_titles=(\n",
    "                f\"{ticker} Stock Price with Key Events\",\n",
    "                \"Sentiment Patterns\"\n",
    "            ),\n",
    "            vertical_spacing=0.15,\n",
    "            specs=[[{\"secondary_y\": False}], [{\"secondary_y\": True}]]\n",
    "        )\n",
    "        \n",
    "        # Plot stock price with key events\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=stock_daily.index,\n",
    "                y=stock_daily['Close'],\n",
    "                name='Stock Price',\n",
    "                line=dict(color='black', width=1)\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Add positive events\n",
    "        positive_events = significant_events[significant_events['event_type'] == 'Positive']\n",
    "        if not positive_events.empty:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=positive_events.index,\n",
    "                    y=positive_events['Close'],\n",
    "                    mode='markers',\n",
    "                    marker=dict(color='green', size=12, symbol='triangle-up'),\n",
    "                    name='Positive Events'\n",
    "                ),\n",
    "                row=1, col=1\n",
    "            )\n",
    "        \n",
    "        # Add negative events\n",
    "        negative_events = significant_events[significant_events['event_type'] == 'Negative']\n",
    "        if not negative_events.empty:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=negative_events.index,\n",
    "                    y=negative_events['Close'],\n",
    "                    mode='markers',\n",
    "                    marker=dict(color='red', size=12, symbol='triangle-down'),\n",
    "                    name='Negative Events'\n",
    "                ),\n",
    "                row=1, col=1\n",
    "            )\n",
    "        \n",
    "        # Plot sentiment patterns\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=sentiment_daily.index,\n",
    "                y=sentiment_daily['sentiment_score'],\n",
    "                name='Daily Sentiment',\n",
    "                line=dict(color='blue', width=1)\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=sentiment_daily.index,\n",
    "                y=sentiment_daily['smoothed'],\n",
    "                name='Smoothed (3-day)',\n",
    "                line=dict(color='purple', width=2)\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=sentiment_daily.index,\n",
    "                y=sentiment_daily['momentum'],\n",
    "                name='Momentum',\n",
    "                line=dict(color='orange', width=1, dash='dot'),\n",
    "                yaxis=\"y2\"\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # Add event markers to sentiment chart too\n",
    "        for event_date in significant_events.index:\n",
    "            fig.add_vline(\n",
    "                x=event_date, \n",
    "                line_width=1, \n",
    "                line_dash=\"dash\", \n",
    "                line_color=\"gray\",\n",
    "                row=2, col=1\n",
    "            )\n",
    "        \n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            height=800,\n",
    "            title_text=f\"Sentiment Patterns and Key Market Events for {ticker}\",\n",
    "            legend=dict(\n",
    "                orientation=\"h\",\n",
    "                yanchor=\"bottom\",\n",
    "                y=1.02,\n",
    "                xanchor=\"right\",\n",
    "                x=1\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.update_yaxes(title_text=\"Stock Price ($)\", row=1, col=1)\n",
    "        fig.update_xaxes(title_text=\"Date\", row=1, col=1)\n",
    "        \n",
    "        fig.update_yaxes(title_text=\"Sentiment Score\", row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"Momentum\", row=2, col=1, secondary_y=True)\n",
    "        fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "        \n",
    "        return fig\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define tech tickers to analyze\n",
    "    tech_tickers = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"META\", \"NVDA\", \"TSLA\"]\n",
    "    \n",
    "    # Initialize visualizer\n",
    "    visualizer = SentimentStockVisualizer()\n",
    "    \n",
    "    # Display correlation for a specific ticker\n",
    "    apple_fig = visualizer.create_correlation_plot(\"AAPL\", days=30)\n",
    "    if apple_fig:\n",
    "        apple_fig.show()\n",
    "    \n",
    "    # Create heatmap of correlations\n",
    "    heatmap = visualizer.create_heatmap(tech_tickers, days=30)\n",
    "    if heatmap:\n",
    "        heatmap.show()\n",
    "    \n",
    "    # Create comprehensive dashboard\n",
    "    dashboard = visualizer.create_sentiment_impact_dashboard(tech_tickers, days=30)\n",
    "    if dashboard:\n",
    "        dashboard.show()\n",
    "        \n",
    "    # Analyze sentiment patterns for Apple\n",
    "    patterns = visualizer.analyze_sentiment_patterns(\"AAPL\", days=60)\n",
    "    if patterns:\n",
    "        patterns.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
